Simulation engine simcity like

Road 1x1, serves also electricity and water
Road coverage 3x3
Building 1x1 for now, needs to be under road coverage
Road as connected component, each road a list of 1 tile building linked to it
Multiple tile building are cumulating their cost to a master tile, which will be the road connection


Demand RCI
Should be a local demand

Lot
* Level 
Indicates potency to meed demand
Capped by density
Increase if conditions met

Residential lot
*** Level 0
* Provides
Nothing
* Requires
1 Water
1 Electricity
Road
4 r demand

*** Level 1
* Provides
4 r unit
2 c demand
2 i demand
* Requires
1 Water
1 Electricity
Road
6r demand

*** Level 2
* Provides
10 r units
6 c demand
4 i demand
* Requires
2 water
2 electricity
8 demand met


* Commercial Lot
*** Level 0
* Provides
Nothing
* Requires
1 Water
1 Electricity
Road
4 c demand
*** Level 1
* Provides
4 c unit
4 r demand
2 i demand
* Requires
1 Water
1 Electricity
Road
2 demand met


Demand RCIO
Demand defined as the difference between actual unit and target unit.
time taken to raise level if requirement reached, then a new lot if none in waiting


asks 8r
Plop 2 residentials
electricity water road met
8 r, asks 4c 4i
Plop 1 commercial
8r 4c, asks 4r 6i
Plop 1 industrial
8r 4c 4i, asks 8r 2c 2i
Plop 1 residential
12r 4c 4i, asks 4r 4c 4i
Plop 1 commercial 1 industrial
12r 8c 8i, asks 12r 2c 2i
Plop 1 residential
16r 8c 8i, asks 8r 4c 4i
Plop 1 commercial 1 industrial
16r 12c 12i, asks 16r 2c 2i
Plop 1 residential
20r 12c 12i, asks 12r 4c 4i
Plop 1 commercial 1 industrial
20r 16c 16i, asks 20r 2c 2i
Plop 5 residential
40r 16c 16i, asks 0r 12c 12i
Plop 1 commercial 1 industrial
40r 20c 20i, asks 8r 10c 10i




4 res = 16r asks 8c 8i
2 com = 8c asks 4r 4i
2 ind = 8i asks 4r 4c

10 res = 40r asks 20c 20i
5 com = 20c asks 20r 10i
5 ind = 20i asks 20r 10c



***Algorithm for RCIO resolution

**Strategy 1: Road container based

Road network
Electricity/water
Each road can ask used and total capacity
Disconnected roads have different capacity

Function master check
Get next candidate for resolution
Check maintenance requirements
If maintenance requirements not met
  Downgrade? Disable? Provide no income? Upkeep cost? finish
Check level up requirements
If level up requirements met
  Upgrade, finish

Function check maintenance requirements
If none
  Finish ok
if need electricity
  If used > total capacity
    Finish no
If need water
  If used > total capacity
    Finish no

Function check level up requirements
if need road
  if no road, Finish no
If need electricity
  If not enough free capacity
    Finish no
  Add usage
if need water
  If not enough free capacity
    Finish no
  Add usage

A building provides units to a road.
A building has demand, starts from the nearest
road, and explore until it finds a free road
with free units.
If a building is removed, its units are removed
from its road and during the next cycle, a
building that used the road will remove
the full amount of the demand from it.
Number will go below capacity.

The rico statistics are hold in road.


**Strategy 2: Itinerary pair based

Process the simulation by type

Ratio of power/water grid determines income percentage.

Building residential has a requirement to have 
access to x commercial, x industrial. 
Remove all previous traffic. 
One traffic itinerary is set as a list of 
waypoints. 
Remove all traffic itinerary. 
Note that removing a road will not remove the 
traffic itineraries that go through this 
deleted road. 
They will naturally be deleted the next time 
the building is resolved. 
Starting from building location, 
explore the grid to find free commercial 
capacity, free industrial capacity, 
taking into account the existing traffic. 
Once a building is found, add an itinerary. 
Add back congestion level.

For converging to an optimal solution and 
reduce traffic, two buildings with overlapping 
traffic could exchange itineraries that cross 
each other. 

**Mechanism 1: Arbitrary building resolution

The scanning is arbitrary and starts at the
beginning of the map.
It iterates over the map index by index.
Alternatively, it can also moves in a building
queue, but the logic of adding and removing
from the queue must be solid. An example can
be a queue that grows as building are added
in fifo way. As a building is destroyed,
the tile is added to the queue, and scanning
an empty tile will just make it not queued the
next time. This way, scanning is performed
in a more economical method. In any case,
best is just a function that returns the next
tile to resolve (there may be no buildings).
Placing a building or replacing it will
update its sprite, but not its simulation data.
The simulation data is updated only upon
resolution.
The simulation data will hold a different state
than what is shown upon a change but it is fine.

**Structure 1: Building/Road data table (bits)

A building has an object that holds all the data
it needs for its resolution? or is it through
data tables? If it is table then
Zone id table, 8 bit or 16 bit
Density table, 8 bit
Pollution table, 8 bit
Congestion table (road), 8 bit
Speed table (road), 8 bit
Debug table (road), 8 bit
RICO offer * 4 (road), 8 or 16 bit
Connect tables * 4 (road), 8 bit ot bitmask

Using everything as table may be worthwhile,
but memory consuming?
Road admittedly only consumes, conservatively
a third of the map.
May be interesting to use unsigned int array
tables if they are faster, even limited
to 255 with 8 bit values for memory constraint.

Connect to is 4 direction, which requires only
4 bits, so a number from 0 to 15 is enough.
However, current implementation is holding the
index of the connected route, not just a flag.
Further bits could be considered for further
connection tiles away, which could be useful
for special cases of connections. A 16 bit
integer can then hold connection to 4 tiles
away, which is plenty.

Demand offer bits may have enough with 255 (8b)
then assuming 16b data storage, demand and
offer can be stored in the same field for saving
space.


**Structure 2: Road network specifics

Road network is an example of not array table
based, but hash table based. Array table may
be fine for data that is one value per index.
Hash table will be
necessary for more complex data. A consideration
is the size required for holding a table with
mostly empty data. Todo search hash vs array
memory consumption.
In term of performance, holey array have 10%
the efficiency of a packed array. A holey
array is one where there is an undefined
object in the mix.

**Structure 3: Cantor indexing

Note that the scheme of using cantor indexing
has a big overhead (twice memory reserved vs
compact indexing while only half of it is used)
but it allows extending.
If extending is a goal, then it may be better
to segment the grid into sub units, sub units
have compact indexing while unit grid is hash
based? Display would be limited to
a sub unit.

**Mechanism 3: Acceptable city size and junctions

Sim city 4 small city is 64x64, large city 
is 256x256. It allows region play so there
is that too. But for starters, it is fine,
hence there would be no need to support
extending dynamically, and so a static
indexing would work. However, extending
will be based on region play, So there is
the connection between regions to take into
account. One could say, if a region is a
simulation state, then it could be loaded,
churned into the engine, and updated without
having to display anything.
And so, keeping a sub unit to be 256*256 would
be memory efficient for data tables.
Junction roads between sub units however
need to be smart. For now, a road holds the unit
capacity provided by direct adjacents buildings.
A building having demands will explore the
network to feed on road capacity.
For subunits junctions, it can be thought as
checkpoints. Once all buildings have been served,
roads with remaining capacity can route to
these junctions and add up the free capacity
of that node + actual cost to fill that capacity
(on the sub unit provider).
Then on resolution of the neighbour subunit
(consumer), a traversal that explore the
junction will interpret it as a road with
free capacity (associated with a cost).
A difficulty resides in knowing whether to
settle with the junction, or to keep going.
As you see, a junction has many costs possible
so it does not fare well with bfs exploration.
Indeed in bfs it is supposed to resolve the
demand on a tile that is next candidate for
lowest cost. A solution would be to populate
the junction with many connections, not only
one road.
Once the consumer side has finished, the
provider side needs to update its congestion.
The junction becomes a consumer that has demand,
and must be processed as such by exploring the
network and add back congestion to the roads.

**Structure 4: Road data structure

A road is ultimately a provider first:
The provision unit is as such:
- type: rico
- free capacity to provide
- cost of provision (function of congestion)
- region id
- building location x y
A road should be able to host many provision
units, especially junctions.
A road is next a consumer:
The consumption scheme is more tied to a
building instead of a road.
- type: rico
- demand unit
- region id
- building location

One could make a provider table and a consumer
table, in the fashion of entity component system
A road holds a list of indices to buildings.
These indices to buildings are used both for
the provider and the consumer.
A building is also connected to a road,
possibly.
Add a road, then a building?
Road will attempt to connect, fail because none,
then the building will attempt and succeed.
A road has a list of connected positions on map?
Or it is a cache of the value?

Or, a zone table, and an id table. The id
is a entity. A provider component, a consumer
component, and other things components.
ECS may have poor performance though? Not
necessarily. At least it is similar to the
road network

An alternative would be to build roads first,
then zones after. This way the zone is tied
to the road? 

Can this scheme be performed at smaller level?
For example, a sub unit is 32*32.

Interesting bit on memory
https://stackoverflow.com/questions/45803829/memory-overhead-of-typed-arrays-vs-strings
That says typed array have quite some overhead
compared to strings.


**Structure 5: Saving in JS

Can use localstorage.setItem('key','content')
with content being string. It requires using
serializable objects...
Either each module writes its separate object
with a key (ex ASZONE_ID, ASROAD_id), or
write one big object that holds all necessary
state and break it down further the line.

**Structure 6: Save data structure

After some reading, the complexity of a system
depends on the reading pattern.
The likely reading pattern are:
- roads read other roads and properties on that
road (demand, unit, etc)
- view reading that is about display of tiles

Most evolution of the system will happen locally
over roads so a game state is better constructed 
from one master structure for each tile, or road 
tile and eventually more advanced structures 
elsewhere in needed.
Only the display part will not be able to be
memory efficient.

The structure may be
x
y
display tile
road or not road
debug
electricity provision + / consumption -
water provision + / consumption -
rico provision + / consumption -
pollution
if not road
  x road
  y road
if road
  congestion
  speed
  connectup
  connectdown
  connectleft
  connectright
  list of connected buildings?

The game state will be a hash of those, or a
array. Modules such as aszone and asroad don't
hold data themselves, but work on this master
game state. This master game state is what is
saved. The data layer is retrieved from this
master structure.
This however will require indexing to be
the same for all modules. Either its initialized
with a table size x/y to allow compact indexing
or just using a hash table.

  
**Strategy 3: Agent based Demand Offer

A building has offer and demand.
Example:
Res building offers 6R, demands 3C and 3I.
Offer is registered at the nearest road.
The road knows it has 6 free R offer out of 6.
Upon resolution, building starts at road
and moves until it finds the 3C and 3I.
One R fills one C or one I, and adds 
one unit of congestion.

It could be agent based, where a building does
not know its agents.


**Strategy 4: Statistics based simulation

A building offers res and ico. The number
of rico will affect the traffic in the immediate
surrounding. The more a road has met demand,
the more its congestion. Congestion should
bleed to neighbors. Road networks should
know their total rico capacity and current use.
Congestion affects road efficiency, hence reduce
income. One could see that if a 100 ico demand
is met, then it bleeds 100 congestion unit
in the neighbourhood in a gaussian fashion.

The logic is that when there are many people
wanting to go to a high demand location
(high ico) then the surrounding area are busier.

This could lack the realism of agent based,
because in highly specialized districts
the traffic is supposedly unidirectional,
but this scheme would spread traffic in
concentric circles, hence you would have
two centers of traffic, and nothing in between,
regardless of the nature of the road between
the two districts.

**Strategy 5: Car agent based

Consider the network. Each building has a demand.
The demand is a dynamic variable that increase
as time goes, and decrease as cars reach it.
The demand has a maximum value, and cannot
increase over it. It is demand capacity. The
demand capacity increases as the building
grows. The building grows if the demand reaches
zero for some time (ie it is filled). The
demand capacity decreases when it reaches its
capacity for some time. 
A key factor is the rate at which it decreases.
It must decrease at the same rate an equivalent
demand is generated.

**Strategy 5.1: Car aggregate alternative

Each building has a offer, that depends only
on its level. Multiple buildings can aggregate
their offer. The aggregate becomes a car that
moves in the network and fills the demand.

**Strategy 5.1: Per building car alternative

Or it could be a car per building.
This is fine too, that data can be stored
per building.

**Strategy 5.2: Car generation

Car capacity is defined by density.
Car volume generation is defined by density.
That is a high density zone will generate
cars often, a low density zone will generate
slower.

**Strategy 5.3: Car based congestion

Congestion works over time too. When a car moves
from a road to a road, the congestion increases
by its remaining demand. This may seem absurd
because some cars will take a longer road.
So high density will plug all road capacity
when it just generates its car. Why not, this
emulates rush hours.
How does speed impacts whether a car moves to
the next or not? Maybe road capacity is a
sufficient indicator, that is is road has
available capacity, moves, else wait.

This removes the need of knowing which demand
ties to which offer. It is even fine if a car
moves for an undetermined time?

**Strategy 5.4: Algorithm

Resolving a building car is:
Initialize
- Generate a car at nearest road
    set x y
- Fill it with offer RICO
- if road capacity is not free
    skip and wait status
    end
- move status

Move
- remove current car offer from road capacity
- if neighbour road node has full free capacity
    set x y to new road node
  else
    set x y to current road node
- fill in building demand with car offer
- remove filled car offer
- if car offer is zero
    wait status
    end
- add car offer to current road capacity

Machine state
waiting status
  initialize
move status
  move

**Strategy 5.5: Timestamp relation

The system is time driven. It has a queue of
timestamps, where the next event should happen.
A building has at max one event in the queue.
If not using queue, then buildings can be
pooled, and the event check is happening
periodically.
Car movement is defined by road congestion
and road speed. Next movement happens at a
timestamp function of the road speed and
road congestion.

If using a queue, then this structure is
[index, timestamp]. Problem is to keep the
queue ordered at all times.
Timestamp is not save/pause friendly, so it may
be better to use a internal timestamp that is
incremented when there is a update loop.
This internal clock must be saved.
In javascript, max integer is
Number.MAX_SAFE_INTEGER, so there is a check
to perform here.

**Strategy 6: Area of effect based

A building is processed at a certain time. 
It has an offer to distribute, which is the
remaining out of a max offer.
It has a distance balance. The distance balance
depends on its density level. It could also
be a function of its max offer.
Or it could be a max value that does not change
for all buildings. 
The building starts at the nearest road, and 
travels from road to road, in a breadth first
depth fashion.
For each road travelled, the processing is:
- 0/ Among next road traversal candidate
     (including starting road):
     - if it is blocked, skip (go 0/)
     - if it is available, go 1/
     - if no more roads, go 3/
- 1/ increase road congestion level by the sum
     of offer. It should be fully possible.
     Check the nearest buildings in four
     directions and fill their demand,
     except its own building.
     Retrieve the cost of the tile so far.
     If distance balance < cost, go 0/
     else, go 3/
- 3/ For all traversed roads, remove remaining
     offer sum (that is the surplus of offer
     that was distributed in the 

Blocked road definition is:
- no road
- one way road at opposite direction
- not enough capacity to hold influx of
    congestion

One thing to consider is when a building can
reach more than one distinct networks of roads,
then it should be accessing the additional
networks if its offer is still filled.
Supposedly, traversal is able to be initiated
with a few starting points.
The current implementation however supposes
that there is one starting point and the
traversal starts from it, as saved from the
data. This is how the whole cache is built
from a starting point.

Not adopted
Alternatives are assuming buildings as
traversable tiles, hence building can be a 
starting position.


Alternative is altering the road network
by adding a special tile that has up to 4
connection points to nearest roads, then
consider that point as a starting point.
But from a datastorage point, it is not
possible to save it as a conventional road.
There are missing fields for nwse connections.
Moreover, the connection was changed from
getting an index to getting a direction to
the nearest tile, while here it is about
jumping two tiles away. One could use flags
to indicate how far away the connection is.
The data needed for the building is connection,
but it should not need anything else.
This connection should be recomputed each
tick, as road structure may have changed.
Or one must assume it is always updated
accordingly when a road is deleted, avoiding
recomputation.
This is ideally a one way connection, as we
don't need traversal to go into buildings.
Or, if building lookup is time consuming, then
the connection can happen bidirectional, so
roads don't need to perform building lookup.
Traversal must exclude building targets, and
only accept road targets. They can however
start from building targets.
Connection can be done as roads and buildings
are built. That means connection check should
be a common implementation between asroad and
asrico.
Implementation must cover:
- connect upon placing roads, done
- connect upon placing rico
- check upon refreshing node list cache



** Strategy 6.1: Road speed modelisation

Cost can be an inverse of speed.
Cost is an increasing value that starts at 0.
For the same road, the cost is kept minimal
when the flow is good.
For example, a city road that flows well
has a speed of 50, which is like a cost of
200/50 = 4. If the city road has a few cars
(offer car passing by), its cost stays at
4. By the time more cars are passing through,
speed is going down. For example, the threshold
can be 30 cars per tick.
Cars are instantaneously added, but they
dissipate with time, so this is how traffic
is simulated.
A 50 km/h car is going through 900 meters per
minute, 15 m per second. Two cars spacing
is therefore 15 m to keep full speed.
If you consider that a tile is 100 meters wide,
then 6 cars get in at full speed and the tile
is full. That is, a tile max speed capacity is
7. The exact formula could be:
tile length TL = 0.1
tile max speed in km/h TS = 50
Max speed threshold is:
TL / (TS / 3600)
TL / TS * 3600 = 7 cars
Below 7 cars, speed is maximal. The cost of
this can be 200 / TS, which is 4.


Assuming an acceptable commuting time is 1 hour
then the max distance under roads of 100 m tiles
at 50 km/h is 500 tiles.
This is too big of a scope, but why not.
Commuting time can be reduced to 30 minutes,
which is 250 tiles away.
TM = 0.5 in hour
For a TS 50 and TL 0.1, the max distance is
TM * TS / TL = distance in tile for TS roads
Assuming arbitrarily that the unit cost is
200 / TS, then the max distance as cost is:
TM * TS / TL * 200 / TS
TM / TL * 200
That means the max cost is 250 * 4 = 1000 units.

Traversal going through a city road will
increase cost by 4, as long as there is less
than 7 cars.
Once there is more than 7 cars, then
the speed limit becomes what separates two cars
by one second TD.
Say, if a tile has n cars, then
TC = n
TL / TS * 3600 / TD = TC
TS = 3600 / TD * TL / TC
And we get a degressive speed.
Say, 
7 cars  50 km/h 4 unit : green
9 cars  40 km/h 5 unit
11 cars 33 km/h 6 unit
13 cars 28 km/h 7 unit
15 cars 24 km/h 8 unit
for 100 cars, 3 km/h, 66 unit
This holds for single lane, bi directional road.
If we consider roads with multiple lane, then
TS = (3600 / TD * LN) * TL / TC
which makes the road capacity increase.


Experiment shows that congestion successfully
stop buildings to grow. By adding other paths,
building find other ways and resume growing.
With lane count in picture, the range goes
further.



Assuming road decay in place, congestion
naturally falls as time pass. However, if
offer is not recharged, then the traffic is a 
one time thing.

Recharging ponctually causes cyclical traffic,
which is hard to diagnose from a user point
of view.
Recharging not at the same time is causing
unstable hot spots.
Recharging every turn could be a solution

Does that make sense?
Road decay as of writing is function of
the number of cars, and will gradually
increase as the capacity cannot absorb all
the traffic in one tick, leading to a deadlock.

The key parameter for this is the tick duration.
A 1 min tick shows a decay of 6% for 1000 cars.
However, a tick of 1 hour shows a decay of
360 % for 1000 cars, and 100% for 3600 cars.
That means if there are more than 3600 cars 
added to the network per hour, the network
can handle it fine. More than that and it will
show signs of accunulation, leading to potential
deadlocks as the flow increase more than the
network can absorb it.
A flow based one could be just adding flows
in the path. If the flow is lower than the
network decay capacity, it is green.
If the flow is almost at capacity (above 80%)
ot is a yellow situation. If it is above
network capacity then it is definitely red.
How is defined road capacity?
As an example, 1000 cars (TC) go through a 100m
road (TL) limited at 50 km/h (TS max), and 
cars are separated by 1 second (IC). The 
observed duration is 1 hour (TD).
By decay rule, these cars can all go through
the patch in 1 hour.
Indeed, a car runs 14m per second, and 
one car go through the 0.1km patch in
a little more than 7 seconds. 
Two cars go through it in 7 + 1 seconds.
1000 cars go through it in 7 + 1000 seconds.
3593 cars go through it in 7 + 3593 seconds.
This is the maximum flow capacity of the road.
There is a missing detail of cars being too
close to each other, or that the road can
only fit 7 cars at all times.

Assuming a highway of 90 km/h, same distance,
a car runs at the speed of 25 m/s, and cover
it in 4 secs. In 1 hour the road can see flow
3596 cars at most.

The formula is
time to cover tile length = 
  tile length / road speed
LD = TL / TS

total car flow per tick =
  lane count * (tick duration - time to cover)
TCF = LC * (TD - LD) / IC
    = LC * (TD - TL / TS) / IC
This formula causes negatives values for very
small tick duration, as long as the time to
cover it is bigger than tick. It is definitely
flawed because the number of cars that get it
is supposedly the same as the number of cars
that get out.
Under this assumption the new formula is only
dependent on IC and TD, and no matter the
road speed, the flow is the same (flow per
tick). This is true if we consider cars as
abstraxlct points. As speed gets lower, 
assuming cars of length zero allows fitting
an infinite number of cars in a limited space,
as long as speed is not zero they will be
separated by one second.
Assuming:
a car runs at one meter per second,
the inter car is one second,
the tick duration is one second,
then the cars leave at a rate of one per tick.
However, for cars of length 3 meter,
the cars leave at a rate of one every 4 tick,
so the max flow dramatically drops as speed
lowers. But this only applies to speed which
covered distance during one tick is lower than
car length. It is in fact a constant added into
formula.
A car runs (TD * TS) meters in a tick. 
The second car is CL + (IC * TS) meters away. 
The timing to see 2 consecutive cars is 
(CL + (IC * TS)) / TS = (CL / TS + IC).
The flow per tick becomes TD / (CL / TS + IC).
For roads:
2 5 14 25
Flow do vary by speed, which is satisfying.

Lane is the biggest multiplier for flow. 
IC is unlikely to change.

For load to be distributed correctly among
possible routes, flow needs to be taken into
the traversal cost. As of now, only the speed
is what determines the traversal cost.
It is fine that a route is taken until its flow
reaches peek, then traffic moving to another
location. A road that has reached maximum flow
must have reduced speed, at a fast rate.
One can consider that flow over max capacity
will decrease the road speed, at a rate that
it takes additional time to travel, and
thus reduces the speed by the same amount.
That is:
speed reduction factor =
  current flow / max flow
The rational is for a road of 0.1km of speed
50 km/h, cars cross it by 7 sec. It holds
3593 cars max in one hour. However, if they 
were 7186 cars wanting to cross at the same
time then you would need to cram twice the
number of cars inside the same space.
Assuming you need to increase the density, while
keeping the same IC, then speed must be reduced.
A sustained flow runs at 14m per second.
Cramming the double while keeping IC requires
to get to put in the same space twice more cars
and therefore reduce speed by two.
Hence speed is reduced, and cost of traversal
too.

Is it realistic to assume IC to be 1 second?
There are issues such as road lights,
intersects, which will reduce or cut the flow.
Sustained constant flow is more the realm of
highways and long flat roads.
So a possible action is to consider IC as a
road parameter.
Highway: IC = 2s
Straight Road: IC = 4s
Crossroad: IC = 5s
Crossroads are likely bottle necks for flow,
which is even more exacerbed by being 
point of traffic crossing, but it makes sense.
Not applying a malus is fine too.

Upon offer dispatch, the entire offer is added
as flow thorough the path. Car count is
discarded as a stat to keep.
There is no concept of road decay, as simulation
is run every tick. One can consider that decay
is a possible source of confusion. Changing
the layout will be for the better.

A red situation is indicative of high flow,
and that overtime the road is surcharged
and congestion will start to appear.
What could be the negative impact of this?

Will traversal equilibrate the traffic?
Possibly. As the car count is still real,
the speed is affected, as is the cost. So
some buildings could also not be able to be
served due to traffic car count, which is
the desired effect.

But this depends on whether all buildings are
resolved each turn, or if they are inactive
sometimes.

Roads don't need to be reset, the decay system
is still useful and will lead to congestion,
with buildings not being able to provide
their offer or receive demand, and as such
the influx of car will diminish as it reaches
an equilibrium but still busy.

After adjusting the tick duration and how
maxflow behaves, and introducing the car length
there is now not only a max flow, but physically
a max capacity, i.e. how many cars can fit
the space within a certain time. The maxflow
at top speed assumes all cars go through
one by one separated by intercar duration.
Hence when tick duration is 1 hour, say they
are something like 2500 cars crossing. In fact
this is the absolute max amount of car that can
crosses it. By reducing the speed, you would
reduce the number of cars that can fit.
Hemce maybe it makes more sense to not allow
more cars going through that road, which
is synonymous to setting speed = 0.
Current maxflow in truth depends on current
car speed, while we do approximation that it
should use car speed. But it may seem unfair
to set the speed as 0 if flow reaches the max
as the theoretical max flow can support that
many cars. So if flow is below max flow, then
it should make sense that decay is 100% and 
speed is maintained. 
Currently car flow does not depend on speed
or maxspeed, it only assumes every ic there
will be a car leaving.
If there are many more cars however, that means:
- decay cannot absorb that many cars and there
will be cars left at the next tick
- It should not be possible to fit that many
cars within the tick
- speed may be decreased. Should decay be
impacted? It seems to be a dangerous loop, as
speed goes towards zero due to congestion,
the number of cars to leave a tile is also
reduced, and so the number of cars stays
stagnant, which causes a congestion that leaves
only after quite many ticks, while it should
be able to clear out quick.
- should speed is either max or zero? The
implications is the road will be taken until
it reaches max flow, then other roads will be
taken immediately. In fact it is maybe a fine
modelisation, as the road physically can only
hold so many cars a day.
Then the next tick it is supposedly cleared.

Should congestion bleed then? As a form
of decay. Like, the number of cars that do not
get absorbed are dispatched in roads arounds
so as to clear the congestion, i.e. do not
rely only on the decay to clear up.



Example solution?


** Strategy 6.2: refreshing rate

Map wide refresh

A refresh every turn is likely the best for
predictive simulation, although overall
simulation will slow down as the number 
of building grows.
It has a good advantage of not having to
process roads separately, and they can
be processed in one go. Only thing is an 
initial pass to reset all buildings and roads.
Eventually one additional pass for the closing
of a tick.
Performance wise, it has advantages. Some
operations can be performed much quicker
because they are done map wide, such as
road reset, refresh or decay. Cache locality
is helping big there.

Different systems can also be refreshed at
different rates, assuming they are independant.
For example, road network can be updated every
tick, while rico can be updated every 3 tick.
Although ideally, every tick for every one
is the best.

Roads don't need to be reset, the decay system
is still useful and will lead to congestion,
with buildings not being able to provide
their offer or receive demand, and as such
the influx of car will diminish as it reaches
an equilibrium.

To avoid pitfalls of always the same buildings
being refreshed first and having the advantage
on the traffic, it could be a randomised
refresh order, ensuring equilibrate refresh
advantage. Priority can be based on when it
was refreshed previously. But it might be
not the best in term of performance.

The roads need to be refreshed with one single
pass, to apply the decay. However there may be
a unsync with the graphics so there should be
a 'displayed value' which is the value of
the last peak before decay, and the current
flow value which is changed by buildings.

This way, roads is processed first,
before buildings, over the course of a tick.
Keep it that way.


Individual random refresh

It may make sense to refresh entirely a 
building in a single pass, that is
level checking, reset offer and demand,
then dispatch offer, and individually without
interference from other buildings. Although,
offer may be not distributed to building that
don't have been reset yet. Which in the overall
picture is relatively okay.

However for road networks there is a dependency
between all road tiles for it to be consistent.
That is, they must be updated all at once,
be it that there is decay or not.
A gradual decay is graceful, and realistic
looking, but it is taxing the simulation.
However that way all buildings have a relative
equal chance toward the traffic, instead of
the buildings having an advantage when they are
processed right after the roads have been reset.

With more gradual update, it may make sense for
roads to be individually decayed because
statistically they are updated at the same rate.
This could solve the dependency issue.
Either they are decayed one after the other in
one go, or in between. I want to try updating
individual cells.



** Strategy 6.3: rico and road exchange

The area of effect stops once the commute time
capacity is depleted.
The distribution is through an area of effect.
The area of effect follows roads, starting
from the building. It follows all roads in a
breadth first depth. Upon checking a road,
it transfers the offers to free buildings
around, raises the congestion of that road
followed so far.
Fullfilled demand decreases over time.
Congestion decreases over time.
High congestion reduces the spread of the
area of effect by consuming more commute time.
The building will therefore
only serve near zones, nearest first.
This looks like the most realistic.

Max distance is a function of building
level. Remaining distance is reduced by
traversed road congestion level. 
In exchange, congestion level is increased
by the offer count. 
However, if road congestion level cannot
hold the new offer count under its max, it is 
blocked and cannot be further passed until its
capacity frees. The traversal must keep working
the other tiles though, because there may be
free capacity elsewhere.
A problem with this rational is that past
cars are impacting future traffic.

If distance is covered (or all roads are 
blocked) then the traversal comes to an end,
and the remaining offer (that was added to the
network) comes in deduction of congestion level
of passed roads.
The rational for this is this surplus offer
has no destination and should not exist on
the network.

This implementation shows an issue:
The cost is increased in roads even if the
destination is not there, which makes circles
of congestion even though traffic is one way.
The way to better implement is to add congestion
not for the whole offer, but add congestion to
all tiles from building to destination amount
to filled offer. This is more consuming, but
ultimately is realistic of traffic.
There is then no removal of surplus offer
since they are added on use.

The next observed oddity is offer tends to
be distributed to the nearest demand, which
makes further building starving.
Putting 3 buildings RIC is not necessarily
equilibrate: upon leveling unfilled order is
lost. A way to circumvent this is to keep
residual, non filled offer across leveling
up.

** Strategy 6.4: Road decay time

What about the decay time for roads? 
It is about how long is a tick.
If you consider a tick as a minute, then
TS / 60 = 50 / 60 = 833 m in one minute. That
makes a tile quickly empty in normal cobditions.
With 3 / 60, only 50 m in one minute. That is
in one minute, 50 / TL ratio of cars have left
the tile, making it effective for large
traffic. So the formula for traffic clearing
is TS * TT / TL, where TT is tick duration in
hour. If ratio > 1, tile is cleared.
If ratio == 1/3, only 1/3 is cleared.

One tile of road consumes 
TS = LN * TL / TC / IC
   = lane count * tile length / 
       car count / inter car
reduction ratio i.e. how many cars leave
  = TS * TD / TL
  = tile speed * tick duration / tile length
  = LN * TL / TC / IC * TD / TL
  = LN / TC / IC * TD
  = LN / TF / IC * TD (updated)
ex: 1 / 100 * 3600 / 60 = 0.6, i.e in 100 cars
in a 100m long tile, speed is 3,6 km/h which
is 60m per minute. So 60% leave within 1 minute,
assuming they all fit.
Leaving the tile is leaving the network
altogether.
This is a criteria that makes traffic
unbalanced.
Assuming 100 cars in 100m, 60% disappear per
minute on the network.
Assuming 1000 cars in 1000m, same speed
conditions, 6% leaves on the network.
A better equivalent is 100 cars in 1000m
So assuming 10 tiles of 100m for 1000m,
60% disappear which is very unbalanced compared
to 6%. Although this is actually 10000 cars.

One way could be, if 1000 cars must travel
1000m, then they are stuck at 3.6 km/h.
It is the same speed as 100 cars wanting to 
travel 100m, but the difference is the cars
disappear quicker from the network.
1000 cars leave the network at a rate of 6%,
per minute.
So to have a rate of 6% per minute. Each tile
of 0.1 km should be marked by 1000 cars.

But, say, 100 cars must travel 1000m. Their
speed is 36 km/h, and they run 600m in one
minute, hence they leave at the rate of 60%.
Say, 100 cars must travel 500m. If they all fit
in a tile, then they drive at 18 km/h.
Therefore they drive 300m in one minute, and
60% leave the network.
Hence regardless of the distance, 100 cars
leave the network at the rate of 60% per min,
assuming they have constant speed on the path.

If 1000 cars must travel 10000m, then
their speed is 36 km/h. they run 600m per
minute, which is leaving the network at 6%.

So, the decay is not a function of the speed
in theory, only of the car count.

But saying that, each tile is supposedly
marked by 1000 cars, either they run 10km or
1km. Each tile with an equal number of
cars will empty at the same time. But marking
1000 cars for a 1 km target or 10 km target
changes the road speed. And the speed defines
the cost in congestion.
This means 1000 cars if spread to 10km target
is same as 100 cars if 1km target, 10 times.
However cars must leave the structure.

So maybe, there should be 2 figures. The actual
number of cars on place TC (1000 cars over 10 km
is 10 cars per 100m tile), and the number of 
cars on the network TF (1000 cars on 10 km, 
which is a leaving rate of 6%). The 6% is
applied both to the number of cars on place and 
on network.

The actual speed is decided by the cars on
place.
The decay rate is decided by cars on network.

Cost stays the same, relative to speed.

** Strategy 6.5 : building recharge rate

As road congestion decays, building rico
levels needs to recharge, otherwise road decay
will prevail and roads gets empty.

A simple strategy is to reset demand and offer
every tick, and consider a building level up
only if the building demand has been filled,
as well as other conditions.
That is, a partial fill does not count for the
next tick. Every tick starts at the same state
in term of road traffic and building offer
and demand.

Not adopted
Normally, the traffic is equal day to day, and
should dissipate as going into the next day.
Hence offer is recharged per day. Eventually if
I consider a day as 8 hours, then the tick
number is 8 hours / tick duration, which means
8 ticks for full recharge, and so demand and
offer recharges 1/8 of its capacity every tick.
So the recharge rate is tick duration / day
duration of maximum. Same for demand or offer.
But offer start at zero, and raises during the
day. Same for demand.

Not adopted
If one was to divide the maximum offer and 
demand, then it becomes as if each tick is
similar. So offer and demand increase is the
full amount. Then, a level up is basically
if maximum offer has been dispatched, while
maximum demand has been consumed. The amount
will simply depend on the tick duration.
As demand and offer is supposed to be
multiplied by the tick duration, the scale
is very important to avoid overflow issues.
For the time being, the data is 16bit, which
is equal to unsigned 65535 or signed 32763.
This is supposedly the maximum offer per tile
regardless of tick duration. It is
potentially limited. Assuming a tick duration
spans from 1 second to 14400 seconds, it leaves
very few margin. It is also unlikely to setup
1 offer per second.
So, the alternative is to:
- setup floating point demand and offer, which
may not be good with int16
- setting x100 integers, but this reduces the
maximum capacity
- move to int32 for the full asstate
- additional field for 32 bit number based
on two 16 bits numbers
- setting a fixed offer and demand max that
does not depend on 
The offer and demand per tick could be a
static number in a known range, then the flow
added will depend on the tick duration.
Now is understanding what range of numbers
are likely to be provided per tile.

So, finally, assuming demand and offer 
depends on the tick duration, then as long
as all checkboxes are filled at the beginning
of the tick, then an exp point is added,
and the demand / offer is reset. Scaled
offer and demand is the way to make sure
long tick duration is not an advantage due to
downtime.
The exp amount may depend on the tick duration.
Offer is likely too small to be divided as. 
a proper integer. The observable range is
1 fu to 50 fu per day per tile.
Hence, there are 4 alternatives:
- enforce a tick a day
- discrete distribution of fu every x ticks,
which is somewhat realistic, but implementation
may be tricky, as that would mean distributing
each offer at a different rate, hence at 
different ticks. I guess demand is the same
and it is to be dispatched thoroughly.
- floating point distribution, which is
data dependant and inconvenient as of now
because of no 16 bit.
- Offer and demand as is, but its signification
depends on current tick duration. That is, 1
offer and 1 demand per tick, when a tick is
1 hour, means eg 1 fu. However, 1 offer and 1
demand when tick is 1 minute, means 1/60 fu.
How does that impact the flow?
Car flow is therefore divided by it too.
Indeed somewhere the car flow must be divided.
Assuming there is 4 hours per day then every one
is going out between 6am to 10am.
Current implementation is absolute flow, the
number of cars that will go through this road
today, or a tick duration max of 4 hours.
Assuming you multiply the flow by 4 artificially
(same rate, repeated 4 times, tick 1 hour),
the flow is stored multiplied, so as to make
sure it is always incremented by 1 at least.

then you have to divide the car flow by 4
when computing the decay or the speed.
So the flow becomes a flow per tick.
The factor is computed by having day in sec
being 3600*4, and flow divided being
tick in sec / day in sec.
Maybe the number is too low to be displayed
as such.

In the end, the flow signification can depend
on the tick duration, same as offer and demand.
It is a matter of interpretation, not simulation
as the offer and demand is the same regardless
of tick duration. What changes however is the
maximum flow that depends on duration, ie as
duration decreases, maxflow decreases, while
offer/demand stays the same. Maxflow is in
theory an absolute value, but now becomes
maxflow per tick.

The next thing is how speed is controlled.


** Strategy 6.6: Density and buildings

If a tile is 16mx16m wide, 
a (1x1) tile is:
- one house no garden
- one tile of road
a (2x2) tile is below
a (3x3) is 48mx48m
A hotel and its parking
My home.

If one is to consider a 32x32 wide block, 
a (1x1) tile is:
- two houses and two gardens 
- one house with big garden
- a medium size 5 stories

Considering a family unit, it is 2 parents
2 dependants.
2 parents go to jobs.
2 dependants do other things, but don't count
for unemployment. They count for population.

Paris urban density is 21000 / km2, that is
about 0.21 / m2

Light density housing: between 0 per tile to
5 per tile. No consideration for wealth?
Max 2 storey buildings
1x1 ie 16mx16m
- 1 $   1 fu / 1. 1st home
- 2 $   2 fu / 2. 2st multi family
- 3 $   3 fu / 3. 3st multi family

2x2 ie 32mx32m
- 1 $   5 fu / 1.2. 5 1st homes with street
- 2 $  12 fu / 3.   2st dormitory like
- 3 $  20 fu / 5.   3st hlm

3x3 ie 48mx48m which is an acceptable size.
That would suppose road reach is 3 tiles
away, which is not yet possible. To consider?

Medium density housing: between 5 and 20 per 
tile? Max 5 storey buildings

Maybe it should require 2x2 tiles to fill.
Or maybe not, parisian buildings are narrow.


1x1
- 4 $   5 fu / 5. 3st fatter chain building
- 5 $   8 fu / 8. 4st fat building
Cannot go higher

2x2
- 4 $  32 fu / 8.   5st hlm
- 5 $  48 fu / 12.  7st hlm
- 6 $  72 fu / 18.  10st hlm

High density are 20 upwards
1x1 cant go higher

2x2 32mx32m
- 7 $ 100 fu / 25.  14 st hlm
- 8 $ 144 fu / 36.  21 st hlm
- 9 $ 200 fu / 50 . 30 st hlm

even bigger buildings should be unlocked
by 3x3 buildings


Another strategy is to recharge the offer, as
well as demand as tick increase. Tick duration
would be a criteria on the rate of recharge.
With a sufficiently long tick duration, it is
equivalent to a full reset of offer and demand.
When a job is filled, it is filled for the day.

Rate of offer recharge will increase road
traffic, so both must be equilibrated, as well
as decay. One can consider only what happens
during rush hour. It is a limited time where:
ro -> id : jobs being filled
ro -> cd : jobs being filled
co -> rd : clients
co -> id : clients
io -> rd : clients ?
io -> cd : restock
It is a bit awkward but equilibrated.

Unemployment is residential offer, commercial
and industrial demand not filled.
Poor clientele is commercial offer not filled, 
ie industrial demand and residential demand not
filled.
This kind of symmetrical demand and offer
is fairly boring.

One could consider the following model, which
is more in line with cities skyline and simcity
mechanics.
Residential desirability is:
- low traffic = road property
- service coverage = service demand
- commercial access = com demand
- jobs = res offer filled
r -> c
r -> i
c -> r

Commercial desirability is:
- high traffic = road property
- service coverage = service demand
- employment filled = res demand
- industry stock = ind demand
- customers = com offer filled
c -> r
r -> c
i -> c

Industry desirability is:
- transport variety coverage
- service coverage = service demand
- employment filled = res demand
- customers = ind offer filled
r -> i
i -> c

For those to be equilibrate at a 1:1:1 rate,
Residential 
offers 20r
demands 10c

Commercial
offers 10c
demands 10r
demands 10i

Industrial
offers 10i
demands 10r


Not adopted
An alternative can be that demand is kept over
time, while being a lot more bigger than offer.
It becomes then a sort of gauge to fill until
it is ready to upgrade. This indicates past
performance is kept (it may decay thought).
Offer on another hand is x times lower, and
slowly fills demand. The advantage to this
is a well served building will evolve quickly
but that also means on building that is first
reached by offers will hog it all from all
sources. So this is not a viable strategy.

Not adopted
A basic decay can be that every day (which
is benchmarked to 4 hours?),
the recharge is full. So every tick duration
the offer comes back at a percentage of that
rate.
Should you decay demand too?
It depends on how the level up situation is
decided. 
* It cannot be a 'number of ticks',
because low tick duration has the possibility
to increase many times the number of ticks.
* It could be an absolute duration, defined
by the number of ticks, which number depends
on tick duration. There may be a discrepancy
between high tick duration and low tick duration
in the behavior of the system, and downtime
during high tick duration is counted as filled
more quickly than low tick duration.
* when demand is filled, is it consumed?
Demand can instead be a buffer, where it is
slowly consumed to produce value towards the
level up. Hence the role of decay.
It could be something such as, building has exp.
One exp point attribured when all filled:
- 3 demand filled
- 1 service filled
- 1 traffic related factor filled
- 1 offer filled
So a building demand can be saturated until
one of these factors is reached. Could work.
Should a building offer saturate too?
This could lead to dead roads though, if there
are two buildings which demand is filled, so
they don't take offers and it does not convert
into traffic leading possibly to conditions
that will never materialize.
So maybe demand is never saturated. It always
take in resources, and that count for exp.

A building generates offers, and when they find
a demand it generates income through tax. It
also serves as a level up leverage. However,
find no one to consume your offer and it
sits. Sitting offer is still offer so it is
fine, it just does not generate income.
On another hand, a building generates demand.
But if it does not generate anymore demand
then it is blocked. Not generating demand is
not normal, it is a lack of growth.

So, r generates jobs, while c and i consume
jobs. Consumed jobs make income tax.
I generates goods, and c consume goods.
Consumed goods generate industry tax.
C generates sales, and r consume sales. This
includes the 'service industry' such as eating,
medical, ... It generates vat.

Can a building stop consuming? Best not.
Otherwise there may be deadlocks.
So a building has offers; no offers filled
means no customers or unemployment, which
leads to reduced desirability and abandonment,
or level downgrade. Say offers unfulfilled is
tossed, to generate demand. So a building
does not stop demanding.
Level up is probably something like multiple
gauges. It is easy to fill up if it is demand
or service, but it is not the case if it is
offer and all.

There is then the condition whether the optimal
conditions must be maintained over some time
continuously, to level up. If not maintained
then it is reset, or decreased.


Road traffic property can be a booster or a
malus.

Traffic can be assymetrical: 
* res offer, residential to commercial / 
industrial count as traffic.
* ind offer, industrial to commercial count as 
traffic. Heavy one could be an interesting 
twist to increase traffic.
* com offer, commercial to residential can be 
trafficless contribution because it seeps into 
residential neighboorhood traffic, and it is
detrimental. But it could also be emulating
how residential look for commercial zones.
* service offer can be trafficless contribution


Pocket city does it cleanly.
r -> i is jobs
r -> c is shopping
i -> c is manufacturing to selling


Cities skylines buildings stay within the
confine of their zoning. That is, a low
density zone will only ever grow low density
buildings, and a high density zone will
only grow high density buildings. Level
is independant from zone, as there is low dens
level 1 just like there is high dens level 1.
Once reaching max level, there is no evolution
from low dens to high dens.
Hence there should be no concept of zoning
evolve. It simplifies the simulation to do
it like this.
Hence, there can be just a concept of density
level within the confine of a zone, but we can
increase the levels.

Current implementation of having ric offer and
demand exhibits some flaws under specific
configurations. For example, 6 res and 1 ind,
with 1 com at the other side. None will level
up because the ind offer, needed for both com
and res level up, is distributed towards a res,
so the com cannot level up. In other words
there is a competition between ressource, which
will make growth uneven or impossible.
The way to fix that is for one resource to be
provided to one zone. That is:
c demand jobs (from r), goods (from i), offer
services (to r)
i demand jobs (from r), offer goods (to c)
r demand service (from c), offer jobs (to c)

Hence there are the categories:
jobs
goods
services (to distinguish from public service)

c: 1 job, 1 good, produce 2 service
r: 1 service, produce 1 job
i: 1 job, produce 1 good

Using this assymetrical dependency chain,
buildings grow, correctly even with surcapacity
although industrial requires less space for 
the time being. It will be a matter of raising 
the capacity. This is a matter of the ideal
proportion one wants.

* Strategy 6.7: building level up and down
Sim city 3/4 had a wave effect of buildings
getting abandonned then refilled cyclically.
An unstable system like this probably needs
time to stabilize.

With the initial implementation of 5 level
buildings, they were growing and shrinking
non stop, as a building was levelled down
immediately if its demand was not met, but
that was not the case in a 3 level structure.
Probably, a level 5 building is able to
fill most buildings around and was starving
the others. Probably there was also a chain
effect, by growing inadequately, there was
demand that was left unmet.
Should a building grow because there is
demand for it? it is kind of the case for
a building to grow to the next level, when
a residential has a demand for commercial and
induatrial.

Now, there should be a timing for level up,
where a building levels upon a certain time
as opposed to leveling when the conditions
have been met. 
This could either be implemented through some
kind of exp which amount depends on the tick
duration. Exp raises when all factors are
met, and decrease when the factors of the
previous level are not met anymore. This is
important to distinguish the conditions for
levelling up or down, otherwise there is
no stable condition over which a building
has reached a plateau.
The implementation is
do parent init + do leftover - do init <= 0

Maybe there can be a sustained effect using
macro stats. 
For example, if demand is bigger than offer,
then a building is not authorized to downgrade.
This could eventually block the moving of
people.

A building growing spontaneously is problematic
in it grows and capture demand that makes other
building not growing in places that are more
relevant. A building growing because it captures
the offer of nearer buildings could be fine
as it expresses people moving to better or
nearer locations. The question is can a level
zero be requesting demand, for it to spur
growth? It is seemingly a good idea. However,
it results in all buildings needing a demand.
For a residential to grow, there needs to be
a com offer and ind offer reaching the tile.
Otherwise it cannot work. The demand must
come from somewhere.
Commercial and industrial may require only
residential so as to start, at level 0, to avoid
growth.
Residential level zero maybe don't need
any demand, but not sure about realism.

High density will need to capture, but what
about low density? It could be allowed to
grow spontaneously, so as to start a new
neighboorhood.

Since traffic is resetting every tick, there
is also the problem of priority in roads,
where some buildings will always have priority
over the others in taking the available space
in roads which may lead to starving buildings,
just maybe. The actual effect is uncertain.
Because there is no reduction in speed as
traffic gets higher, only the last building
to cross the road is impacted. The others don't
have a particular advantage over the order
the buildings have 


** Mechanism 6: Road traversal

Classic implementation is breadth first.
A separate data structure could work fine.
See Mechanism 7 for the impact of a separate
data structure.

Implementation shows that a road is added at
most only one time to the data structure, in
particular the 'to' is unique.
However, this only allows one parent. Since
it is a tree, it is not possible to get the
childrens nodes. How do you get the leaves?
If you start from a leaf you can get to the
root but not the reverse.
Or, in fact you could. Roads have the connected
information (north, south, etc). So knowing
the root, one could navigate up to leaves.
Therefore saving the state of a traversal
could be possible, although maybe
slightly computation intensive because
there is no way to know which are the last
leaves except by traversing the tree from the
root. But I could try.

A traversal data structure had the benefit of
being savable, and many could run at the same
time. Moving to a storage in the grid makes
it impossible to run multiple traversal paths
at the same time. Hence, no multicore on a 
single state. That is not a bad thing though,
since multicore makes things unpredictable.
Multicore will be available in running multiple
independant simulations.

**Mechanism 6.1: Road traversal on grid

The requirement is that the data structure
contains all leaves on a list, which
incrementally grows as traversal goes,
and a lot of the elements are refered by their
indices instead of an other key. The index
is the unique key taken into account, because
this is the order of storage in the old data
structure. If it was any other key, that would
mean to perform a lookup each time a data must
be accessed.

Changing to the to index as a key could be
good.
A new algorithm could be that.
From a starting point, register the cost (the
road capacity), the parent (none), and the
processed flag (added, not traversed).
Lookup for the leaf with the lowest cost,
that is added not traversed.
The lookup is performed at the start, and
since there is only one leaf, choose it.
It becomes traversed.

Child leaves are naturally connected, so check
the isConnectedTo instead, and if they have no
added flag, connect, and initialize their cost,
their parent, and mark them as added not
traversed.

Which leaf should be traversed? The one with
the lowest cost.

Note that it is necessary for a node to have
3 states, not processed, added, and processed.
The added state (yellow) indicates a node
that is reached and will be one of the next
candidates.

The transition to this new method requires
a transition from a edge graph to a node
graph, and a change to the whole algorithm.
As a change to, the starting node is a
traversal added not reached.

To get the next step, the algorithm must be:
From the start
check all directions
if one is traversed and is not parent,
  put it in a queue to process
if one is added,
  put it in a queue to costify
do that until there is no more to process.

next, process the costify queue.

This is why it is best to get the first tile
as a processed, so the exploration towards 
four directions is correct.

The performance bottleneck stems from
getCurrentNodeList, which is basically the tree
of traversed tiles. For the time being it is
built each time it is needed (eg identify next
node), but most of the structure is in fact
repeating and only one value is added each
time it is built.
The risk of keeping the table instead of
aleays recomputing one is about unsync,
if for example data is loaded during a
traversal. Hence why it is safe to always keep
it refreshed.
One needs to take care of these cases.
Performance wise it should be relatively linear
as the table keeps growing by adding indices at
the end. The order may be unimportant, this is
to test, and will greatly simplify the
process of keeping a cache.

Cache node optimisation (G_CACHE_NODE):
- without worker, 180->30 per tick
- with worker, 116->30 per tick
Only caveat is notifying caches to invalidate.

** Mechanism 6.2: Road change during traversal
Current implementation is able to sustend the
following situations:
- adding a road linked to untraversed road,
traversed roads, and roads in waiting
- removing untraversed road
However the following situations will result in
invalid state:
- removing traversed road or roads waiting
to be processed.
The root cause is the reupdate of the node list
cache, at which time the cut down portion of
the path disappear from the list and cannot
be reupdated.
*A solution may be to reset the path upon
updating. This allow a clean state for all
roads before adding / removing a new link.
The implication is a road traversal is likely
ongoing, so there need to be support of
traversal being invalidated during the machine
state. Which means it can impact the 
distribution of offer/demand at a key time.
*Another solution could have been to not reset
some fields upon replacing roads, but it does 
not solve the problem with removing roads.
*Another solution is to replace the road only
when a traversal has been completed, i.e.
locking the road network for the duration.
To do this, a buffer is possibly needed in top
of addRoad, and this buffer is cleaned upon
starting updateBuilding. Same for removeRoad.
This is to introduce a safe time to process
orders. This queue does not need to be saved
in data state, but surely needs to be cleaned
upon load/save.
A traversal should be short enough to see no
latency is this.
The only possible problem I foresee is that
the data id changes only when the simulation
is playing. Upon pausing, no road or building
is actually put. There needs to be a phantom
placeholder I believe, in place of the tile
being replaced, for the duration of the
next turn. Doing it that way probably needs
an additional field, which is like "waiting
for change". Upon requesting its id, the tile
is using a building site instead. It could
also be a phantom tile looking like the one
to be placed, but just with an alpha. Alpha 
tile is not supported under current rendering
strategy though.
*Another strategy, looking similar to the
previous, is a field in datastate, which is
nextZoneId. SetZone freely sets it, but the
engine is the one commiting it at its pace.
That way, graphically it can be already
displayed as both, or with a build site
placeholder. That could also allow change of
planning as long as it has not been commited.
The commit could either happen during a tick
or after the tick, but always upon traversal
end.
The difference is that the order is saved
and can be resumed, i.e. no cache of setZone.
But if there is a need to process the setZone
asap, then there is a need of a queue of some
sort, which means it needs two fields instead
of one in datastate, plus 2 fields in global.
If no urgency, then it is processed as part
of update tile routine, in which case it is
almost fine: the simulation can handle it
when in need, but it might take some time
to complete, maybe up to 10 seconds for very
big cities? For roads, as long as it is
completed before the next tick, i guess it
is okay.


** Mechanism 7: Checking all buildings

For now, one can just pool over all buildings
until the tick is reached.
Pooling experiments on 96x96 work fine, but
on 128x128 it is at a crawling speed.
It looks like a critical mass at this threshold.
Therefore priority queue seems in order,
or a tick happen over the course of multiple
frames. The later solution may be complex
because i have to assess how much time i have
until the next frame and how much computation
I can fit in this time frame.

The checking is done until the capacity is
depleted, in the same tick if possible.
Otherwise one must save the state of the check.
Can it be done on the grid? Possibly, as a
variable. That means there is only one single
trip check at most within a tick. System 
is updated each frame loop until aoe is
depleted.
Buildings are not checked all at once in the
same tick, there need to be a timeout before
it is checked again so offer distribution can
occur sparsely.
Trip check could have been saved as values on
the grid, but is now saved as a data structure
stand alone, and could be saved as such in
save data, assuming there is always only one
data structure. The caveat is memory size is
not fixed.
// struct is
// array = [
//   from of starting point
//   last explored index,
//   number of edges,
//   collection of edges * 5
//   ]
The from is unique. If it was saved in the grid
then processing would have to scan for it to
find it.
Same with last explored index.
Other alternative is to never save game if there
is a traversal path in progress, i.e. a game save
occurs always at the start of the next check,
even if it occurs during a tick.
Other alternative is to save the state on the
grid. The traversal state is saved into the
grid. However, the current implementation is
not compatible with interrupting a traversal
in the middle. The update unit is a tile.
The tile per call/frame depends on the framerate.
The traversal necessarily finishes at the tile.
One could change the system to a number of
checks instead, lets call them cycle.

A cycle can be defined as one action that
consumes a little time. The cycle per frame is
capped dynamically.
The checking should be organised in steps:
- For demand, checking if the demand is met
counts as one cycle even if it is very
short. For now at least.
- For offer, increasing the traversal state
and all surrounding buildings and adding to
their demand is one cycle.
Hence there must be two flags to track the
progress:
- which building is being checked
- which step is being run

So, should building be scanned one by one?
One way to do this is to chain buildings
through adding order. A building will hold
the next and previous building to scan.
Holding previous and next is obligatory,
as well as holding one point of entry, such
as the last building added.
That can work as a circular linked list.
Destruction of a building must be ordered

Road checking may be more complex.
A corner might be checked up to 4 times from
4 directions, hence it may be filled up multiple
times.
One could also set a flag on a building, that
indicates which next tick the building demand is
authorized to be updated, which is tick + 1.
Upon checking a road, all buildings within 2
blocks on 4 directions are tested.

How do i know when to stop checking?


Observed a crawling speed on performing
resetTraversalPath at step 3 (after
traversalPath finishes). resetTraversalPath
is too big of an operation that does not fit
a frame cycle, unlike the others. Consider
performing reset traversal path over
multiple cycles, or performing the commit
change log over multiple cycles.
The solution of commiting change log over
multiple cycle is interesting, because that
could batch modifications at a rate controlled
by the render. One could also say, next tick
does not happen until the change log is all
empty.
It happens that the asroad change log exploses
in size (from 80 to 800 in 16*16 grid and 5*5
road square) when a reset traversal path is 
performed.
The actual formula for the change is this:
Road has 3 changes per traversal, it is
traversed by as many buildings as there is.
More importantly, a road is added multiple
times in the commitChangeLog, hence a road
is repeatedly asked to be refreshed, because
it is added in the changelog multiple times
before it is processed.
So, we can do a policy to always empty
the change log before moving to the next
update tick, or the next frame.
What is the render policy?







**Mechanism 8: System ordering vs framerate

The systems could work as such:
All systems that need to be updated are run
once per loop. If they are ready to go to next
tick, they return true, else if they have
remaining tasks they return false. Tick stalls
until all systems are green.
They have in input the current tick, and the
remaining computation time for the current
frame.
Systems are executed in turn. Only when one has
finished computing, that is it moved to the next.
Computation time is distributed with a counter
tied to fps, that is if it is slowing down,
the next framerate will process less tiles.

Graphical refresh was relatively linear in the
number of operations performable.
Adding multiple steps after that in which the
steps are not homogeneous is more difficult.

There is two level of cycle comsumption
The first level is the graphical engine.
MMAPRENDER
If a frame got skipped, that means there are
too many calls to refreshTile and you have to
reduce the number of tiles to refresh.
The second level is the computation engine.
ASRICO and ASROAD
They have a large number of computation to 
perform over a lot of tiles, and if the frame 
skips, then the computation needs to tone down
and its allocated cycle per call is reduced.
Minimum is one machine cycle, which is the 
basis of step by step computation.

Speed measure may be necessary to regulate
the number of ticks as the complexity of the
city increases, which induces a difference in
simulation speed. Stabilizing the number of
ticks is a way to control the simulation
speed. It could be done as a max number of 
ticks per second, and once the limit is
reached on that second it skips. But this
induces a non uniform simulation speed
which may impact the smoothness. To increase
the smoothness, the speed could be not
ticks limit per second but one tick per x
seconds. Hence we have a direct control over
how fast the simulation happens, and it
is made regular.
As of now, a tick will happen over many frames
anyway.
It is also an opportunity to induce frameskip
to increase further simulation speed. That is,
the tick happen, but the graphical refresh 
is performed after more ticks. This frameskip
will induce to hold a "refresh flag" for
each tile, that way we avoid redundancy.
Or we could also have a set of tiles to
refresh which holds only unique values.
The refresh could therefore be done over
multiple frames.

Tick speed is now a value that shows the
frequency.
-1 is stop.
1000 is one tick every 1000ms. Speed 1.
100 is one tick every 10ms. Speed 2.
0 is max speed. Speed 3. However, it seems
the tick speed is limited only to 60 per sec,
owning to the speed of the refresh call.
It could be interesting to go even further.
The strategy will be to consider that rico
must use the maximum amount of cycle it can
before it triggers a slowdown. However, this
must be done separately from graphical refresh.
It cannot be implemented in rico, as rico
must stop upon the tick finishing to let other
systems update (polution, energy, etc).
It must be updated at higher level such as
zone or map. For now, the tick decision
is at zone level.

The decision to make smoothness key requires
frames to never be saturated, i.e. never skip
a frame.
A full call therefore must not use more than
16 ms, or 33 ms depending on target fps (60 or
30).
The flow can be:
- Retrieve time
- Refresh a number of tiles
- Refresh a number of simulation cycle

The render refresh is for now processing a
number of batches per update call. The number
of batches per call is adjusted according to
previous calls, if it was too slow then
it is reduced. It is in fact necessary because
the actual effect of the batches is only
observed at the next frame, ie in the current
frame I set x batches. Once update is finished
the batches are processed and only then do
I know if x batches were too many (because
frameskip), or if they were within capacity.
It is especially important to keep some budget
at the end of the call to process the number
of batches promised.
Strategy can be to update a number of batches.
Consider a fixed budget of 16ms.
Consider a render budget of 10ms. 
Consider a compute budget of 6ms.
Number of batches to process (nbtp) is set.
*fully processed = nbtp > number of batch wait
*frameskipped = dt over
If not fully processed not frameskipped, 
  raise nbtp by 1,
  keep the render budget the same.
If not fully processed frameskipped
  keep nbtp
  raise render budget (reduce compute budget)
  if render budget maximal already
    reduce nbtp
If fully processed not frameskipped
  reduce render budget.
If fully processed and frameskipped, 
  raise render budget.
The strategy seems to be able to maintain a
stable framerate. The comparison currently
done is a asrico loop exit once date reaches
the time limit. However, the comparison is
performed every cycle so it might be expensive.

A possible improvement is batching cycles, if
and only if the date.now call is expensive.
Date.now does not seem too expensive according
to jsperf. Profiling is required.

The next problem comes now in the commit log
queue.
It might be a design decision to make sure the
tiles are updated before simulation engines
run. Updating the graphics is done by
mmaprender, and the amount of sprites to update
depends on the commitchangelog.
The data is changed by the systems, but
the commitchangelogs are order to reload
textures. However, the texture is reloaded
only if it is within the visible range.
The implementation of commit change log queue
has the drawback of accepting multiple times
the same tile except if the structure is a
set or hash or fized array. In the case of
asroad, a road tile is added multiple times.
In the case of a tick that is interrupted in
the middle, the mmaprender is refreshing each
time. Which is... possibly fine for debugging?
Consistency may require buildings to be updated
only between ticks, not within one. But for
debug purposes it is desirable to see the
advance during turn. It however decreases a lot
the simulation speed, but it is in fact a 
secondary speed control, in the sense that
you can vary the rate at which graphics update
(such as every tick, every x ticks, or within
ticks) by imposing a starting condition.

To speed up the refresh of graphics of tiles
that have changed, a possible implementation
can be using a sort of linked chain.
A fifo is most desired for consistent
across frames update. Hence for a fifo to
work a tile must hold the index of the next
tile to update. Hence when adding a new tile
the change flag of the last tile must point
out to the newest added tile.
The algorithm is as such:
Adding to the list
- if first tile is empty
    set first tile = cindex
- else
    retrieve last tile, pindex
    set pindex change flag to cindex
- set cindex change flag to cindex
Removing from the list
- if first tile is empty
    end
- else
    retrieve first tile 
    set first tile equal to ft change flag

Since the max size
is known, it could be stored as a grid flag.
Hence writing multiple times the same tile
will trigger a refresh. A loop could pool the
grid to build a updatedtiles structure, which
is used in place of the commitchangelog one.

Is it a waste of space? Would it be better
to use a datatructure such as set or hash?
Ultimately I will unlikely store more than
512*512 amount of data (256kb), and I am likely
to store instead 128*128 (16kb) of data.
A direct array with some logic is not 
too much wasted space compared to a texture.
Writing it into the asstate may be too much
due to the fact that it is not a sim data,
it is a rendering issue which is supposedly
changing independently from sim data.
However a small issue happens for the sim engine
because engines may have a direct call to
data or render layer, and this is superfluous.
A better option could have been flags in
asstate, which is independant. Change flag
can have other uses outside rendering, such 
as bulldozer. A bulldozer option is saying
that the tile needs cleaning; can it be done
without tick waiting? 
The change flag needs to be processed at the
end of the tick, which will process in the same
tick the render change, and in the next tick
the building orders.
The map refreshing can either happen before
engines updates, in which case we see all
intermediate states (but is slower) or it
can be put after all engine updates, in which
case we don't see anymore the intermediate
state.



**Interaction during simulation

A point of detail about adding and removing
tiles: the actions must be validated between
ticks. Otherwise, if a road is deleted during
a tick, the traversal state may break at reset
and some roads will stay visited and will
never be available for further traversals.
Hence actions must be synchronous, but orders
are asynchronous.

To implement this, a possible implementation
may be:
- process of actions at tick end/begin only
    this requires a way to cumulate orders.
    Once tick starts or ends, the tiles are
    changed accordingly to their new state
    and their state changes, their clock reset.
    
- order cumulation may be:
    a buffer state, in the grid
      pro: it is saved in save state so
        actions are remembered
      pro: only one future state per tile
      con: to link to the change flag mecanism 
        for knowing when changes happen
    or a buffer user interaction
      pro: memory economy
      pro: direct access to which tile has
        changed

If I harness the change flag mecanism, then 
it limits its capability in updating the 
display during a frame (which relies on it
happening in-tick).
So the orders are to be processed between two
engine ticks, so the engines can run on new 
data. 
The actual changes requires upon destruction
are:
- reset of any future queue
- change of road network
- must not affect distribution

The commitDataChange was at first a graphical
need, that could run separately from the
simulation engine and hence separate from
any tick consideration. That way, graphical
update happens when it can. The only
consideration is it takes some compute time
out of update loop so the speed decreases.
Note that graphical refresh happens anyway
for mmaprender (map drag), only the refresh
of new tiles is concerned.

If I link the action buffer to it, then it
becomes tied to ticks. It may be a necessity
if we consider other uses of the change flag.
However one could also consider two queues,
one for hidden data change, one for visible
graphic change.
Most parameters changes must be passive (that
is the data is changed but its dependencies
are not affected until they query the data).
Exception may be roads water electricity.
A change in the data must be trigerred for
visible change, but hidden data does not
warrant it.


About engines, for now ASZONE is the only
one. The tick system is integrated in ASZONE
but could be taken out and put in ASMAP
instead. But ASZONE could be the master
fot tick based simulation, ie all other sim
components could be hosted and coordinated
by it.

Graphically, the difference between a order
in progress and the actual building could
be ghosts or translucid tiles, stating change
is in progress.


** Performance and compute vs render
Grid of 4*4 zones, total 9 zones, each zone
only outer zone being residential.
Road about 112 blocks
Residential about 108 blocks
- at 60fps, on pc, 
small speed is 23 frames
mid speed is 23 probably, 390 ms per tick
high speed reach the same, hence even computer
can not process the full cycle.

One optimisation performed is moving
addRoNodeList to its own function, it saved
quite a lot of time and possible reduced from
700 mspt to 300 mspt on mobile (to confirm).

One possible place of optimisation is the
avoidance of recomputing the current node list,
which now takes about 1/3 of computation time.
The problem with it is the constant recompute
of the whole list, which is the more expensive
the bigger the road network.
There is no requirement for the node list
order.
There is room for a little improvement.
The node list is about getting the road network
that is connected by the traversal.
We know when something is added, that is upon
call of traverseNextNode, its neighbours are
added to the tree.
One possible strategy is to implement a linked
list of the traversal node, in the same manner
as the change flag. I have no lookup 
requirements, only retreiving the whole list.
Once an element is added, it stays in the list
until the whole list is cleared.
So one could save the list as a regular member.
Did I make the choice of having no member
in road and save everything into asstate?
It helps because it makes it independant from
saving loading state, so it is a good thing
probably.

** Webassembly
Input output of webassembly is arraybuffer 
based. Hence each module (zone, road) must 
expose uint32array for the datalayer, and 
the wrapper for the module will colorize it 
accordingly.
Since modules have interaction, the web 
assembly instance is a master object that 
provides multiple datalayers.
The biggest unknown is related to the call to
the engine. As of now, the engine is called
and updated every frame, and the graphic as
well. Hence the engine cycle is performed
every frame, but is only cut into smaller
processing units. By moving to web assembly
the cost of calling the wasm engine may be too
big to be called every frame which would
induce frameskip.

** Web worker
A good alternative to this is having the engine
to run separately from the graphical thread.
The engine would run in wasm, never exiting,
or only exiting after some time, while the
graphic thread would register user ui and
the rest without interruption. That would
require a asynchronous architecture between
simulation and graphic, which is a good idea
to invest in as we are permitted to run both
at the same time without interruption or
inferrence of the time needed. It potentially
removes the need of synchronous change between
ui and engine, and force a asynchronous
architecture. I am treading in unknown
territory.
Web worker is possibly the way to go for this.
It works as a number crunching thread
that communicates with the main thread through
messages.
The mechanism is through using ArrayBuffer
to transfer data to web worker. The reference
is readable by the worker, not the main, until
it is transferred back to the main.
Hence after all the crunching is done for
one or more ticks, we are notified back and the
graphic takes its time to refresh.

Dataflow:
Data resides in ASENGINE as a ArrayBuffer.
The ArrayBuffer is transferred in post message
to the engine worker, and hence becomes
unnaccessible on engine space. The view itself
(Int32Array) probably is not accessible either.

ASSTATE should not be a container for the data,
it should be a wrapper/reader/interpreter for
it. That way it can be used by both engine
and worker.

The architecture can be:
- asmap calls asengine, provides a callback
- asengine process the call, sends messages
    to worker, process the worker's answer
    This requires data to be resident in
    engine, or in worker
- Webassembly could work within the worker
    that would require data to be inside
    worker anyway.
- data should live most of the time in the 
    webworker, for it to be able to handle
    incoming messages.
    Periodically, UI requests a copy of the
    table, makes a copy of it, and send it
    back.
    Or maybe the way to go is just put data
    in the modules, and when needed return
    some values. Hence no back and forth?
    Webassembly possibly does not work like
    that and must have memory provided.
- Worker has no access to any global module,
    and has no way to include any other, so
    it must live in the module file.
- to enable/disable worker, one
    could use a standard message to communicate
    with modules. Either engine directly calls
    them, or send a message to the worker which
    will handle it.
- another issue is the readonly of some
    properties such as table size, where
    there is not much chance that it changes
    accross the run (except at load), and
    hence that global may be read only.
    If however it must be read from asstate,
    then it must be done early in a call.
  UI | Engine | Worker | Module + data


- One caveat is debugging. I would be near
impossible to pause mid tick or during exec.
- Another issue is the graphic refresh must be
reading something else to display, not asstate.
This is particularily problematic for
when ui is switching the view to look at
something else than the master tile data.
What could be done is upon change view request,
the worker can either relax the computation
and give it back for a time, or return a copy
of the table. Making a copy is likely the
safer solution because the copy is saved in
the mmaprender and it allows scrolling with
having to block the worker. A new table
is requested on demand?
- retrievechange is after webworker is done.
saving loading too
- play speed to be excluded from asstate? That 
cycle count does not depend on it in tick,
but may depend on it between ticks.
- Debug window requests
Aszone is in the worker so it is fine; Same for
Asrico and Asroad.
- aszone requires gettablesizex and y are 
required often by render
- aszone requires getdatazonebyid
- aszone setdataid is likely an obstacle
However, mmaprender is using ASZONE, ASROAD
and ASRICO as stubs to access data, via
getDataId. The getDataId is distinct between
these modules. Their definition change 
according to visualization mode and other
things. The returned tileId is therefore not
what is saved on asstate. This may be the main
reason to have a copy of asstate resident in
the ui while there is one in the worker too.
In practice, the tile information are within
modules living in ui space; this is how texture
are built. That means the data interpretation
to tile id could be done on the ui thread,
using data state in ui thread. It is not
practical to request engine to provide the
tile id at each request. So the likely easy
solution is to maintain two asstate, one
being read only. That solution causes an issue
though because retrievechange flag is used
by ui and updated accordingly. Or, changeflag
is processed by engine only and changes are
returned upon request.
Alternatively, MMAPDATA holds a table of cached
tileIds. That table is reconstructed when
switching module, while some indices are
refreshed upon retrieve change (and the tileid
value is also returned?).
Graphical refresh of all tiles is cumulated in
the batchflag, and is processed accross multiple
frames.
How can be the table tile transferred to ui?
Old implementarion had mmapdata read its
target module upon request of refreshTile
and refreshAllTiles. To remove this reading
it would be the engine providing the tileid
values. The possible issue comes from switching
views, where it must request a refresh.
The good thing is the changelog can act as a
buffer and be processed asynchronously.
Possibly, engine is best updating incrementally
so it can be interrupted at all times. However
should some messages be postponed until they
are safe to process? Not sure about the
inplementation.

Web worker has a starting time that is not
immediate, and the ui is ready before the
worker. A change applied is to not block
the ui from displaying a tile if the engine
is not ready but to return an invalid tile
(0, red). Tile info comes later.

Web worker performance is not as good as
expected, but it garantees a smooth ui at
the very least. It is slightly faster because
it makes less updates.
For the time being the engine yields at the end
of a turn.
Step by step update can show all the changes,
but the engine needs to be stopped to get
the resource to process the changes.
Since the worker only yield at tick end in
normal operation, it could be standard to
make it yield also without worker, and to
automatically return the batch of changed
tiles at tick end.
What can be done is one cycle of aszone.update
for one batch of retrieve.change.
In fact, aszone.update could return the changed
tiles? Although that would require some
processing intent.

** Web worker batching messages
Change is handled one by one.
It will be more efficient to retrieve a batch
of it. Same for getDataId, a batching will
be much more interesting.
The architecture can be using a state machine:
- If there are no pending changes, retrieve all 
    pending changes + matching tile ids
- If there is a request, wait until there is
    a response
- When there is a response, put them in
    render changelog and let the render process
    them at its pace
- After there is response, compute

** Visual : UI and data view
As of current implementation, each module has
one view only. This is limiting the potential
as one module could in fact provide many views.
So, there should be a view menu that propose
different views, while there should be many l
function menus.
View menu
  Zone
  Road traversal
  Road congestion
  Rico residential
  Rico commercial
  Rico industrial
Build Menu
  Different zones
Play menu
  Speed
Save menu
  Save
  Load

The architecture could be
One function should be able to build the whole
menu as long as there is the list of tiles, and
identifier, and a level.
buildMenu(library, list, level).
Sprites should be organised into a big table.
Sprites require the library that has the
texture name, as well as a callback when
pressing the function. One is enough.


It is possible that transferring a small
table 128*128 is about 20 ms?
See link for benchmark + demo
https://www.loxodrome.io/post/web-worker-performance/

This might require a full rearchitecture to
separate ui call and engine sim.
The render is stand alone. Upon ui button press
it send messages to the web worker or engine,
which returns the changes.
UI and render are bundled together, while
simulation is separate.
The processing flow changes however. Upon
call of engine execution, there should be
no promise of a return value, no waiting of
the engine. Just a simple do and forget,
except in the cases of;
- save/load
- view switch data
- commit display change
    this one is a possible difficult part
    engine returns now one change at a time.
    would it be more efficient to retrieve
    a batch of changes and processing them
    until depletion?
- getTileTextureName for all sprite
    initialization
    Where should texture name be saved?
    In engine or in render?
    Where should basic texture creation
    happen? Texture creation requires a name,
    and some basic properties such as name
    and color; as of now they are stored
    in a module that executes PIXI objects.
    One could to a standard template?
    Should there be a common definition file
    shared by ui/render and engine?
  even for the graphical part of the city view
  there is a plethora of tiles to assign.
  one needs to retrieve the identifier for
  tiles through a list? Or is it hard coded?
  
There are two kind of operations that the engine
should handle: short direct call and long call.
The short direct call is for small, direct
results that will not make ui thread lag.
Long calls must be message based.
For now, the calls to engine are limited to
retrieving data state and editing tiles, and
this is done through direct calls.
A message based call may work? ASENGINE can be
an experimental intermediate.
The wasm exports functions so the ASENGINE
can be a wrapper for multiple functions.
The form is a table of callbacks. For each wasm
callback a matching ASENGINE call will work.
ASENGINE will function as the glue.

Webworkers are async calls while wasm are
setialized.

** Multi threading
Multicore is very interesting in the sim engine.
There are task that can be processed distinctly.
Spawning multiple workers is a quick way to
speed up, if workload is parallelizable.
Each workload could also work with a webassembly
routine.
It could also be modules working separately.
That means for example that road checking,
which is today saved in asstate, may need to
move separately so it is performable in //.
However that supposes it is not savable and
this limits saving during a tick.
Impacted modules are for example road
distribution and checking.


** Visual : display id
The main display of buildings, the one that
distinguish same zones.
The scope is:

Roads
each type of roads need at least 16 variations.
single plot  0
n  1
e  2
s  4
w  8
ne  3
ns  5
nw  9
ew  10
es  6
ws  12
nes  7
new  11
nsw  13
esw  14
nesw  15
if it is based on 4 flags
n: 1
e: 2
s: 4
w: 8


Buildings:

  

Web worker is started and run sometimes;
it is a good starting point for webasm.



** Linking between asrico and asroad
The current state is the logic of rico point
distribution is handled by asrico.
It could be that asrico only handles leveling
up the states and the points, while another
engine queries which building has things
to distribute and queries asroad to find
the locations.


// ideally, max fps being limited to 60
// the update update cycle runs 60 times
// per second, hence tick per frame
// can be computed. 


Zoning vs display
asrico proposes a view only focused on zoning.
aszone is more general purpose.

Buildings for the time being have only one
progresson axis, in density. Zoning is a way
to limit density, to avoid overflowing the
capacity of the road network.
Density level increase as demand is met.
There is 9 density levels.

Later, progression can be two fold, in density
(user controlled) and in richness.
There will be 3 richness levels.

Touch
On first touch, map always stays under touch
on a static point.
On second touch, it is impossible to keep
static points under touch.
Current strategy is to keep a static point
under first touch, and distance between touch
defines the zoom level.
New strategy could be static point being the
middle of the two touches. When moving two
touch rotation, keep the static point to
middle of the line between two touches.

Implementation requires to know the width and 
height of the screen, in order to be able to
infer the camera map point that makes the static 
point coincide with the middle of the touch.






Search algorithm
Traversing the road capacity requires to know
when to stop, otherwise there will be a lot of
empty traversal. A optimal solution would be
a asroad api that provides the next search
to perform, upon a function call. This requires
to have in input a state, upon which to build.
A step of the algorithm is to have the list of
edges (from, to, cumulative cost) to be explored.
Lowest cost element is traversed, and returns
next edges to explore.

example
a-b-c
  d
  e-f
Starts at d
in: db1, de2 - d
out: de2, ba2, bc3 - d, b
in: ...
out: ba2, ef3, bc3 - d, b, e
in: ...
out: ef3, bc3 - d, b, e, a

What to do in case of cycles?
There needs to be an history of traversed nodes
in input too. Better not to make it a state
for future async calls or simultaneous searches.

Async calls
Multi threading and webassembly specs have not
been specified yet. However, wasm input is to
be copied into the memory of the webassembly
instance, hence you cannot perform simultaneous
searches on the same module with two different
sets of inputs. So the problem of keeping the
state as an input may be not relevant, since
providing an input already changes the state
of the wasm module. An alternative may be to
clone the instance then run a search so
there is distinct memory zones where the
algorithm is working. This is compatible with
Javascript which needs cloning before
performing a search anyway.
There are two key data
- graph traversal data which is mutable
- graph data which is immutable and shared


So the two objects are:
- explored nodes
- next edges to visit

Should we keep it sorted?
Not necessarily, as long as the minimal cost
is being processed. The only thing is it will
need to scan the whole input for the minimal
cost. Appending by insert sort to always keep
the list sorted may be worthwhile? No, because
it will make indices change, see below.

Problem of path reconstruct
When a road has free capacity, it needs to
have an itinerary from start to end.
The itinerary can be built by reversing the
graph.
If the traversal data structure only grows, and
is never sorted, then it is possible to
reconstruct a itinerary because indices will
never change.
An edge requires a parent edge so it can be
reversed.


So far, the structure is a growing data structure
with a collection of edge, with:
from node index
to node index
cumulated cost
parent edge
processed flag

Algorithm goes like this:

function getNextEdge()
retrieve minimal cost unprocessed edge XC
append next edges
  from XC
  to XN
  cumulated cost of XC + congestion of XN
  index of XC in traversal
  false
set XC processed flag
return index of XC in traversal

function pathRetrieval(index of destination)
list
while (XC has parent)
  add XC to list
  XC = XC from parent index of XC in traversal
end
return list


** Texture and tile architecture
Tile id can live in the engine and module space.
It is mandatory to have at least the tile id
enums in that space both for computation.
However, tileId is linked to a texture, 
and require as well:
  - texture name
Texture being initialized for the first time
and never updated, so its is cacheable, even the
name of the texture is cachable easily.

** menu toolbox thoughts
Visibility of a sub menu (at level above 0).
There is only one sub menu visible per level.
How is it decided? Should it be always through
the state of a parent button?
Should it be by class member?
Since there is only one visible menu per level,
it can be a class member. Does it fare well
with concurrent menu visibility? There are
a few menus that can be concurrent, such as
info view vs action zoning. Those two can be
displayed at the same time.
If a menu is out of sight, its functions must
be disabled.
Later, requesting if a view is enabled must
return the correct number even if the view menu
is not the active one. So it cannot be based
on visibility and transparency, and a flag
for currently selected (or last selected) is
necessary.
For now, the implementation will follow a bind
to parent rule, as a parent is hidden all 
children are hidden as well.

So far, the menu architecture follows a permenu
basis. That is the collection is menus, and
callbacks must cover all the actions for all
items in the menu. Hence the collection of
callbacks per item is not straightforward
to store (if the tile enums change in the 
module the struct changes too). 
The menu callback is a pain to write.
Maybe the issue is the tile enum being provided
by the modules, while they are in fact just
a collection of ids.

A menu structure could be a json like.
The leaf can be
{
    tileId : integer,
    callback : function {}
    children : []
}
A parent could be
{
    tileId : integer,
    callback : function {}
    children : [ {}, {} ]
}
the master could be
{
    children : [{}, {}, {}]
}
It is very verbose, so do not do this.

To support scrolling menu, sprites should have
more than pointerdown interaction.

Case 1: 
Press: button
Move: No
Release: same button
Result: button is focused

Case 2:
Press: button
Move: yes
Result: menu should move, so the button stays
below pointer
Release: same button
Result: button is focused

Case 3:
Press: button
Move: yes
Result: menu should move, so the button stays
below pointer
Release: mouse moved out of current button
somehow
Result: button is focused

The data required should be:
upon press, the button is activated anyway.
This simplifies the ui, but need to make sure
there is no undesired actions as a result.
A flag is still trigerred, saying that the
menu level x is moving.
Upon capture of any ui element moving, 
regardless of row, the shift is applied.

Should they be circular menus?

Probably, the way to design the ui is to 
process correctly the intent. If someone wants
to drag the menu, then it is very likely that
one does not want to trigger the button.
One could believe a trigger is about the
shortness of a tap. Hence timing between
up and down is the criteria.


Note that the drag map has a bug where one
should touch in this order, using pointer
down and up.
touch finger 1
touch finger 2
untouch 2
untouch 1
touch 1
upon touch 2, the touch is interpreted as 
touch 1 again
printing identifier will exhibit the issue.
Probably a bug in pixi.